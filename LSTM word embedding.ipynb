{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e815d059",
   "metadata": {},
   "source": [
    "# Fake News Classifier : Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba12c80",
   "metadata": {},
   "source": [
    "Libraries: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf7738",
   "metadata": {},
   "source": [
    "    Link: https://www.kaggle.com/c/fake-news/data\n",
    "    Dataset: \n",
    "        id: unique id for a news article\n",
    "        title: the title of a news article\n",
    "        author: author of the news article\n",
    "        text: the text of the article; could be incomplete\n",
    "        label: a label that marks the article as potentially unreliable\n",
    "            1: unreliable\n",
    "            0: reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca6cb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b739b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake-news/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b61556e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffff3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d15f986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147de641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nan Values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0239891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label',axis=1)\n",
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10b63d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 4) (18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5451756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63132b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d661a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e42c58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Size\n",
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac76d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9d6acd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
       "2                    Why the Truth Might Get You Fired\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['title'][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0647454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have Dropped Nan values before so, reset_index() method sets a list of \n",
    "# integer ranging from 0 to length of data as index\n",
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077bf13",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fe7a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e9a9e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sajwan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea5a0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0,len(messages)):\n",
    "    # print(i)\n",
    "    review = re.sub('[^a-zA-z]',' ', messages['title'][i])\n",
    "    # substituting everything with blank except alphabets\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "# First for each index sentence, except all the alphabets all the words will be subsituted to ' '\n",
    "# then conver each word into lowercase and split each word separately in the sentence.\n",
    "# for each word not present in stopwords then only that word is stored in review\n",
    "# again join the words that were splitted for forming a sentence and append together each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41ea84fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]\n",
    "# all the non necessary word is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63094aa4",
   "metadata": {},
   "source": [
    "### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c15b06ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2163, 2423, 4250, 687, 4939, 4620, 3891, 2358, 3467, 298], [4890, 466, 1320, 914, 2324, 2649, 821], [4551, 2588, 143, 2559], [2788, 778, 3844, 4269, 1582, 2154], [2787, 2324, 3796, 1020, 425, 32, 2324, 3889, 3669, 3939]]\n"
     ]
    }
   ],
   "source": [
    "onehotRep = [one_hot(words, voc_size) for words in corpus]\n",
    "print(onehotRep[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2958a",
   "metadata": {},
   "source": [
    "### Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c975caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0 2163 2423 4250  687\n",
      "  4939 4620 3891 2358 3467  298]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0 4890\n",
      "   466 1320  914 2324 2649  821]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 4551 2588  143 2559]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  2788  778 3844 4269 1582 2154]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2787 2324 3796 1020\n",
      "   425   32 2324 3889 3669 3939]]\n"
     ]
    }
   ],
   "source": [
    "# All the sent have variable len; using pad_sequence fix the len\n",
    "sent_len = 20\n",
    "embedded_docs = pad_sequences(onehotRep, padding = 'pre', maxlen = sent_len)\n",
    "print(embedded_docs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01483bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18285"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebbe5b",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb273096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               56400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_len))\n",
    "model.add(LSTM(100)) # 1 LSTM layer having 100 neurons\n",
    "model.add(Dense(1,activation='sigmoid')) # coz of classification prob\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd486054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final = np.array(embedded_docs)\n",
    "Y_final = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c807f886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 20) (18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape, Y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b71f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X_final, Y_final, \n",
    "                                                test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa540b04",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d95fe190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 11s 39ms/step - loss: 0.3224 - accuracy: 0.8501 - val_loss: 0.1920 - val_accuracy: 0.9183\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.1345 - accuracy: 0.9466 - val_loss: 0.1930 - val_accuracy: 0.9213\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.0906 - accuracy: 0.9655 - val_loss: 0.2200 - val_accuracy: 0.9207\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.0553 - accuracy: 0.9804 - val_loss: 0.2815 - val_accuracy: 0.9127\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.0363 - accuracy: 0.9891 - val_loss: 0.2979 - val_accuracy: 0.9129\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 6s 32ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.3516 - val_accuracy: 0.9112\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.3826 - val_accuracy: 0.9103\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.5059 - val_accuracy: 0.9189\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.4397 - val_accuracy: 0.9107ss: 0.006\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.5797 - val_accuracy: 0.9171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef7aba7e50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain,validation_data = (Xtest,Ytest), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "357a6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the accuracy is 0.9996 almost 1.0 it may lead to overfitting prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd2e2a",
   "metadata": {},
   "source": [
    "## Performance Metrics and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3b080f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.round(y_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ba6900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2816,  291],\n",
       "       [ 164, 2215]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Ytest,y_pred)\n",
    "# False + and False - are very less compare to True + and True -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "193570c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9170616113744076"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Ytest,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5118d6e",
   "metadata": {},
   "source": [
    "## Adding Dropout (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36a99e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150)               114600    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314,751\n",
      "Trainable params: 314,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "## creating Model\n",
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_len))\n",
    "model.add(LSTM(150)) # 1 LSTM layer having 100 neurons\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1,activation='sigmoid')) # coz of classification prob\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6e788b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 13s 49ms/step - loss: 0.3226 - accuracy: 0.8516 - val_loss: 0.1913 - val_accuracy: 0.9183\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.1409 - accuracy: 0.9449 - val_loss: 0.2125 - val_accuracy: 0.9076\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.2293 - val_accuracy: 0.9180\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.0783 - accuracy: 0.9725 - val_loss: 0.2344 - val_accuracy: 0.9125\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.3100 - val_accuracy: 0.9140\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.3496 - val_accuracy: 0.9129\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.3787 - val_accuracy: 0.9098\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.3934 - val_accuracy: 0.9138\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.4378 - val_accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.5060 - val_accuracy: 0.9134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef7f7a6460>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain,validation_data = (Xtest,Ytest), epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
